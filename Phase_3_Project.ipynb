{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Churn refers to whether a customer has stopped using the service or cancelled their subscription.Customer churn is a critical issue for companies, especially in industries with high competition, such as telecommunications. Retaining existing customers is often more cost-effective than acquiring new ones. As a result, identifying factors that lead to customer churn and predicting which customers are at risk of leaving can help businesses develop strategies to enhance customer satisfaction and loyalty.\n",
    "\n",
    " In this project, we used a dataset containing various features related to customer usage and interactions with the service, including account length, usage metrics, service plans, and customer service calls. Our goal was to build predictive models to classify customers into churners and non-churners, helping the company take proactive measures to reduce churn rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The telecommunications company aims to reduce its customer churn rate, which directly impacts revenue and profitability. Despite various retention efforts, there is a need for a more systematic and data-driven approach to identify high-risk customers and understand the key drivers behind churn.\n",
    " The main challenges include:\n",
    "\n",
    "Identifying the most significant factors contributing to customer churn.\n",
    "\n",
    "Developing accurate predictive models to classify customers as churners or non-churners.\n",
    "\n",
    "Providing actionable insights and recommendations to the company based on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Preparation and Exploration:\n",
    "\n",
    "Clean and preprocess the dataset to handle missing values, encode categorical features, and scale numeric features.\n",
    "\n",
    "Explore the data to understand distributions, correlations, and potential factors influencing churn.\n",
    "\n",
    "# 2.Model Development:\n",
    "\n",
    "Build a baseline model using logistic regression to provide an initial understanding of the predictive capabilities.\n",
    "\n",
    "Develop an advanced model using a decision tree classifier with hyperparameter tuning to enhance predictive performance.\n",
    "\n",
    "# 3.Model Evaluation and Comparison:\n",
    "\n",
    "Evaluate the models using metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Compare the performance of the logistic regression model and the decision tree model to identify the best-performing model.\n",
    "\n",
    "# 4.Insights and Recommendations:\n",
    "\n",
    "Analyze feature importance to understand which variables have the most significant impact on churn.\n",
    "\n",
    "Provide actionable insights to stakeholders based on the model's predictions, including strategies for customer retention and areas for service improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By achieving these objectives, the company can leverage data-driven insights to reduce churn rates, enhance customer satisfaction and improve overall business performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data set\n",
    "df=pd.read_csv('Syria_Tel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:From the columns above, we identify our target variable as Churn and the features as all the other columns.In the context of the data set provided, churn refers to whether a customer has stopped using the service or canceled their subscription.When a customer churns it means they have decided to leave the service.Analyzing and predicting customer churn is crucial for business to understand the factor contributing to customer attrition and to develop strategies to retain customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target\n",
    "x=df.drop(['churn','phone number'],axis=1)\n",
    "y=df['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:We drop the phone number column as it does not provide meaningful information for predicting churn and should be excluded from the features used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing sets(50/50 split)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features \n",
    "categorical_features = ['state', 'international plan', 'voice mail plan']\n",
    "\n",
    "# Use OneHotEncoder to transform categorical features and pass through other columns unchanged\n",
    "preprocessor = ColumnTransformer( \n",
    "    transformers=[ ('cat', OneHotEncoder(sparse_output=False), categorical_features) ], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a pipeline to scale numeric features and process the data \n",
    "pipeline = Pipeline([ \n",
    "    ('preprocessor', preprocessor), \n",
    "    ('scaler', StandardScaler(with_mean=False)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1666, 71)\n",
      "(1667, 71)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the training data, and transform the test data \n",
    "X_train_processed = pipeline.fit_transform(x_train)\n",
    "X_test_processed = pipeline.transform(x_test)\n",
    "print(X_train_processed.shape) \n",
    "print(X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and fit the logistic regression model \n",
    "logistic_model = LogisticRegression(random_state=1,max_iter=1000)#to increase number of iterations\n",
    "logistic_model.fit(X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.853629274145171\n"
     ]
    }
   ],
   "source": [
    "#Predict and Evaluate\n",
    "y_pred_logistic = logistic_model.predict(X_test_processed) \n",
    "logistic_acc = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {logistic_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "An accuracy of 0.8536 means that the logistic model has correctly predicted approximately 85.36% of the instances in the test dataset suggesting that the model performs well in distinguishing between the classes.To understand the model performance better we then proceed with additional metrics: precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8219382350991498\n",
      "Recall: 0.853629274145171\n",
      "F1 Score: 0.8296900361785249\n",
      "Confusion Matrix: \n",
      "[[1372   58]\n",
      " [ 186   51]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate Precision,recall and F1 score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "logistic_precision = precision_score(y_test, y_pred_logistic, average='weighted') \n",
    "logistic_recall = recall_score(y_test, y_pred_logistic, average='weighted')\n",
    "logistic_f1 = f1_score(y_test, y_pred_logistic, average='weighted') \n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "print(f\"Precision: {logistic_precision}\") \n",
    "print(f\"Recall: {logistic_recall}\") \n",
    "print(f\"F1 Score: {logistic_f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision measures the accuracy of positive predictions hence a precision of 0.8219 means about 82.19% of the customers predicted to churn were indeed churners.A recall 0f 0.8536 indicates about 85.36% of the actual churners were correctly predicted by the model.An F1 Score of 0.8297 suggests that the model strikes a good balance between the precision and recall making it a reliable metric for assessing the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The confusion matrix shows:\n",
    " i)True negative(1372):model identified 1372 instances where customers did not churn\n",
    "ii)True Positive(51): model identified 51 instances where customers churned\n",
    "iii)false negative(186):There were 186 instances where the model incorrectly predicted that customers would not churn when they actually did.\n",
    " iv)False positive(58);here were58 instances where the model incorrectly predicted that customers would  churn when they actually did not .\n",
    "Therefore high number of true negatives and true positive indicate the model performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 10, 20]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 10, 20]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [2, 10, 20]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a simple decision tree classifier \n",
    "tree_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Define hyperparameters to tune \n",
    "param_grid = { \n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "      'min_samples_split': [2, 10, 20], \n",
    "      'min_samples_leaf': [1, 5, 10]\n",
    "        }\n",
    "\n",
    "\n",
    "# Perform grid search g\n",
    "grid_search = GridSearchCV(tree_model, param_grid, cv=5, scoring='accuracy') \n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.937612477504499\n"
     ]
    }
   ],
   "source": [
    "#Get the best model from grid search\n",
    "best_tree_model = grid_search.best_estimator_ \n",
    "# Predict and evaluate \n",
    "y_pred_tree = best_tree_model.predict(X_test_processed) \n",
    "tree_acc = accuracy_score(y_test, y_pred_tree) \n",
    "\n",
    "print(f\"Decision Tree Accuracy: {tree_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.937612477504499\n",
      "Precision: 0.9360998080701541\n",
      "Recall: 0.937612477504499\n",
      "F1 Score: 0.9366962788212593\n",
      "Confusion Matrix: \n",
      "[[1386   44]\n",
      " [  60  177]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate additional metrics \n",
    "tree_precision = precision_score(y_test, y_pred_tree, average='weighted')\n",
    "tree_recall = recall_score(y_test, y_pred_tree, average='weighted') \n",
    "tree_f1 = f1_score(y_test, y_pred_tree, average='weighted') \n",
    "conf_matrix_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {tree_acc}\") \n",
    "print(f\"Precision: {tree_precision}\")\n",
    "print(f\"Recall: {tree_recall}\") \n",
    "print(f\"F1 Score: {tree_f1}\") \n",
    "print(f\"Confusion Matrix: \\n{conf_matrix_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy:0.9376\n",
    "# Accuracy of 0.9376 indicates that approximately 93.76% of the predictions made by your model were correct. This high accuracy suggests that the decision tree model performs well overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision:0.9361\n",
    "## It suggests about 93.61% of the instances predicted as churns were indeed churners. High precision indicates that the model is effective at minimizing false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score: 0.9367\n",
    "## Indicates a good balance between precision and recall showing the model's fitness in handling both aspects of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "## True Negatives (1386): The model correctly identified 1386 instances where customers did not churn.\n",
    "\n",
    "## False Positives (44): The model incorrectly identified 44 instances where customers were predicted to churn but did not.\n",
    "\n",
    "## False Negatives (60): The model incorrectly identified 60 instances where customers were predicted not to churn but actually did.\n",
    "\n",
    "## True Positives (177): The model correctly identified 177 instances where customers churned.\n",
    "\n",
    "## Thus,these metrics indicate that the decision tree model is highly effective at predicting customer churn, providing reliable predictions with minimal errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  Logistic Regression  Decision Tree\n",
      "0   Accuracy             0.853629       0.937612\n",
      "1  Precision             0.821938       0.936100\n",
      "2     Recall             0.853629       0.937612\n",
      "3   F1 Score             0.829690       0.936696\n"
     ]
    }
   ],
   "source": [
    "# Comparing the performance of the two models using the metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'], \n",
    "     'Logistic Regression': [logistic_acc, logistic_precision, logistic_recall, logistic_f1], \n",
    "     'Decision Tree': [tree_acc, tree_precision, tree_recall, tree_f1] \n",
    "     })\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "## From the results above, it is evident that the decision tree performs better than the logistic model accross all key metrics.It has a higher accuracy and balance precision and recall, indicating it effectively identifies both churners and non-churners with fewer errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actionable Insights for Stakeholders:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Leverage the Decision Tree Model:\n",
    "\n",
    "Customer Retention: Use the model to identify at-risk customers early and implement targeted retention strategies such as personalized offers or improved customer support.\n",
    "\n",
    "Resource Allocation: Focus resources on the segments identified by the model as high-risk for churn, optimizing customer service efforts and retention campaigns.\n",
    "\n",
    "# 2.Feature Analysis:\n",
    "\n",
    "Influential Features: Analyze the feature importance scores from the decision tree model to understand which variables (e.g., customer service calls, total day minutes, international plan) have the most significant impact on churn. Use this insight to tailor services and address issues that drive customer dissatisfaction.\n",
    "\n",
    "# 3.Regular Monitoring and Updates:\n",
    "\n",
    "Model Monitoring: Continuously monitor the modelâ€™s performance and update it with new data to maintain its accuracy. Regularly retrain the model to adapt to changing customer behaviors and trends.\n",
    "\n",
    "Feedback Loop: Create a feedback loop where insights from the model are used to refine business strategies and customer interactions, and the outcomes are fed back into the model for further improvement.\n",
    "# 4.Business Strategy:\n",
    "\n",
    "Personalized Marketing: Utilize model predictions to develop personalized marketing campaigns targeting customers likely to churn with relevant offers and incentives.\n",
    "\n",
    "Product Development: Use insights from churn patterns to guide product enhancements and feature development, ensuring alignment with customer needs and reducing churn rates.\n",
    "\n",
    "By implementing these actionable insights, stakeholders can use the decision tree model to enhance customer retention strategies, optimize resource allocation, and ultimately improve business outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
